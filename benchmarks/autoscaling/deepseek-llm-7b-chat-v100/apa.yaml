apiVersion: autoscaling.aibrix.ai/v1alpha1
kind: PodAutoscaler
metadata:
    name: podautoscaler-deepseek-llm-7b-chat-v100-apa
    namespace: default
    labels:
        app.kubernetes.io/name: aibrix
        app.kubernetes.io/managed-by: kustomize
        autoscaling.aibrix.ai/up-fluctuation-tolerance: "0.1"
        autoscaling.aibrix.ai/down-fluctuation-tolerance: "0.2"
        apa.autoscaling.aibrix.ai/window: "30s"
spec:
    scalingStrategy: "APA"
    minReplicas: 1
    maxReplicas: 10
    metricsSources:
    - metricSourceType: "pod"
      protocolType: "http"
      port: "8000"
      path: "metrics"
      targetMetric: "gpu_cache_usage_perc"
      targetValue: "0.5"
    scaleTargetRef:
        apiVersion: apps/v1
        kind: Deployment
        name: deepseek-llm-7b-chat-v100
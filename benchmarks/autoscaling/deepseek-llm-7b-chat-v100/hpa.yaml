apiVersion: autoscaling.aibrix.ai/v1alpha1
kind: PodAutoscaler
metadata:
    name: podautoscaler-deepseek-llm-7b-chat-v100-hpa
    namespace: default
    labels:
        app.kubernetes.io/name: aibrix
        app.kubernetes.io/managed-by: kustomize
spec:
    scalingStrategy: "HPA"
    minReplicas: 1
    maxReplicas: 10
    metricsSources:
    - metricSourceType: "pod"
      protocolType: "http"
      port: "8000"
      path: "/metrics"
      targetMetric: "gpu_cache_usage_perc"
      targetValue: "50"
    scaleTargetRef:
        apiVersion: apps/v1
        kind: Deployment
        name: deepseek-llm-7b-chat-v100